{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['XB.ELYSE.02.BHV.2019-05-23HR02_evid0041.csv', 'XB.ELYSE.02.BHV.2021-05-02HR01_evid0017.csv', 'XB.ELYSE.02.BHV.2022-04-09HR22_evid0002.csv', 'XB.ELYSE.02.BHV.2019-09-21HR03_evid0032.csv', 'XB.ELYSE.02.BHV.2021-10-11HR23_evid0011.csv', 'XB.ELYSE.02.BHV.2019-07-26HR12_evid0033.csv', 'XB.ELYSE.02.BHV.2022-05-04HR23_evid0001.csv', 'XB.ELYSE.02.BHV.2021-12-24HR22_evid0007.csv', 'XB.ELYSE.02.BHV.2019-07-26HR12_evid0034.csv']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'time_abs(%Y-%m-%dT%H:%M:%S.%f)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Downloads/space_apps_2024_seismic_detection/myenv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'time_abs(%Y-%m-%dT%H:%M:%S.%f)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m cat \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(cat_file)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Conversion de la colonne 'time_abs' en datetime\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m cat[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marrival_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mcat\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime_abs(\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43mT\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mH:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mM:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mS.\u001b[39;49m\u001b[38;5;132;43;01m%f\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS.\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     37\u001b[0m csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcat_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     38\u001b[0m mseed_file \u001b[38;5;241m=\u001b[39m csv_file\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmseed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/space_apps_2024_seismic_detection/myenv/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Downloads/space_apps_2024_seismic_detection/myenv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'time_abs(%Y-%m-%dT%H:%M:%S.%f)'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from obspy import read\n",
    "from obspy.signal.trigger import classic_sta_lta, trigger_onset\n",
    "from scipy import signal\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Définir les répertoires\n",
    "data_directory = 'data/mars/test/data/'  # Chemin vers le dossier contenant les fichiers CSV et MiniSEED\n",
    "output_directory = 'output/'  # Répertoire pour sauvegarder les résultats\n",
    "\n",
    "# Créer le répertoire de sortie s'il n'existe pas\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Obtenir la liste des fichiers CSV\n",
    "csv_files = [f for f in os.listdir(data_directory) if f.endswith('.csv')]\n",
    "print(csv_files)\n",
    "\n",
    "def butter_highpass_filter(data, cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='high', analog=False)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    # ... (Votre code existant jusqu'à la lecture du fichier mseed) ...\n",
    "    cat_directory = './data/mars/test/data'\n",
    "    cat_file = cat_directory + '/' + csv_file\n",
    "    cat = pd.read_csv(cat_file)\n",
    "    \n",
    "    # Conversion de la colonne 'time_abs' en datetime\n",
    "    cat['arrival_time'] = pd.to_datetime(cat['time_abs(%Y-%m-%dT%H:%M:%S.%f)'], format='%Y-%m-%dT%H:%M:%S.%f')\n",
    "    \n",
    "    csv_file = f'{cat_file}'\n",
    "    mseed_file = csv_file.replace('csv', 'mseed')\n",
    "    st = read(mseed_file)\n",
    "    tr = st.traces[0].copy()\n",
    "    tr_times = tr.times()\n",
    "    tr_data = tr.data\n",
    "    starttime = tr.stats.starttime.datetime\n",
    "    \n",
    "    # Utiliser le premier temps d'arrivée (si disponible)\n",
    "    if not cat['arrival_time'].empty:\n",
    "        arrival_time = cat['arrival_time'].iloc[0]\n",
    "        arrival = (arrival_time - starttime).total_seconds()\n",
    "    else:\n",
    "        arrival = 0  # Fallback si aucun temps d'arrivée n'est disponible\n",
    "\n",
    "    starttime = tr.stats.starttime.datetime\n",
    "    arrival = (arrival_time - starttime).total_seconds()\n",
    "\n",
    "    # Calcul du rapport signal sur bruit (SNR)\n",
    "    signal_power = np.mean(tr_data ** 2)\n",
    "    noise_power = np.mean((tr_data[triggers[1]:] - np.mean(tr_data[triggers[1]:])) ** 2)  # SNR après le premier événement\n",
    "    snr = signal_power / noise_power\n",
    "\n",
    "    # Appliquer le filtre passe-haut\n",
    "    fs = tr.stats.sampling_rate  # Fréquence d'échantillonnage\n",
    "    cutoff = 1  # Fréquence de coupure en Hz (ajustez selon vos besoins)\n",
    "    filtered_data = butter_highpass_filter(tr_data, cutoff, fs)\n",
    "\n",
    "    # Utiliser les données filtrées pour le reste du traitement\n",
    "    tr_data = filtered_data\n",
    "\n",
    "    # Initialize figure pour les données filtrées\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 3))\n",
    "    ax.plot(tr_times, tr_data)\n",
    "    ax.axvline(x=arrival, color='red', label='Rel. Arrival')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.set_xlim([min(tr_times), max(tr_times)])\n",
    "    ax.set_ylabel('Filtered Velocity (c/s)')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_title(f'Filtered {mseed_file}', fontweight='bold')\n",
    "    plt.show()\n",
    "\n",
    "    # Initialize figure\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 3))\n",
    "    ax.plot(tr_times, tr_data)\n",
    "    ax.axvline(x=arrival, color='red', label='Rel. Arrival')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.set_xlim([min(tr_times), max(tr_times)])\n",
    "    ax.set_ylabel('Velocity (c/s)')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_title(f'{mseed_file}', fontweight='bold')\n",
    "\n",
    "    # Sampling frequency of our trace\n",
    "    df = tr.stats.sampling_rate\n",
    "\n",
    "    # How long should the short-term and long-term window be, in seconds?\n",
    "    sta_len = 120\n",
    "    lta_len = 600\n",
    "\n",
    "    cft = classic_sta_lta(tr_data, int(sta_len * df), int(lta_len * df))\n",
    "\n",
    "    # Plot characteristic function\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 3))\n",
    "    ax.plot(tr_times, cft)\n",
    "    ax.set_xlim([min(tr_times), max(tr_times)])\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Characteristic function')\n",
    "    ax.set_title(f'{mseed_file}', fontweight='bold')\n",
    "\n",
    "    # Définition des seuils de déclenchement\n",
    "    thr_on = 4\n",
    "    thr_off = 1.5\n",
    "    on_off = np.array(trigger_onset(cft, thr_on, thr_off))\n",
    "\n",
    "    # Création du graphique\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 3))\n",
    "    ax.plot(tr_times, tr_data, label='Sismogramme')\n",
    "\n",
    "    # Tracé des déclencheurs\n",
    "    event_times = []\n",
    "    amplitudes = []\n",
    "    on_label_used = False\n",
    "    off_label_used = False\n",
    "    for i in range(len(on_off)):\n",
    "        triggers = on_off[i]\n",
    "        \n",
    "        # Déclencheur \"on\" (début de l'événement)\n",
    "        event_start = tr_times[triggers[0]]\n",
    "        event_end = tr_times[triggers[1]]\n",
    "        \n",
    "        ax.axvline(x=event_start, color='red', label='Début événement' if not on_label_used else '')\n",
    "        ax.axvline(x=event_end, color='purple', label='Fin événement' if not off_label_used else '')\n",
    "        \n",
    "        event_times.append((event_start, event_end))\n",
    "        amplitudes.append(np.max(tr_data[triggers[0]:triggers[1]]))  # Amplitude max de l'événement\n",
    "\n",
    "        on_label_used = True\n",
    "        off_label_used = True\n",
    "\n",
    "    ax.set_xlim([min(tr_times), max(tr_times)])\n",
    "    ax.set_xlabel('Temps (s)')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "    ax.legend()\n",
    "    plt.title('Sismogramme avec détections STA/LTA')\n",
    "    plt.show()\n",
    "\n",
    "    # Calcul du SNR après filtrage\n",
    "    signal_power = np.mean(tr_data[triggers[0]:triggers[1]] ** 2)\n",
    "    noise_power = np.mean((tr_data[:triggers[0]] - np.mean(tr_data[:triggers[0]])) ** 2)\n",
    "    snr = 10 * np.log10(signal_power / noise_power)\n",
    "\n",
    "    # Résumé des résultats\n",
    "    summary_df = pd.DataFrame({\n",
    "        'Event Start (s)': [event[0] for event in event_times],\n",
    "        'Event End (s)': [event[1] for event in event_times],\n",
    "        'Amplitude': amplitudes,\n",
    "        'SNR': [snr] * len(event_times)\n",
    "    })\n",
    "\n",
    "    # Résumé des résultats\n",
    "    summary_df = pd.DataFrame({\n",
    "        'Event Start (s)': [event[0] for event in event_times],\n",
    "        'Event End (s)': [event[1] for event in event_times],\n",
    "        'Amplitude': amplitudes,\n",
    "        'SNR': [snr] * len(event_times)\n",
    "    })\n",
    "\n",
    "    # Sauvegarder le résumé dans un fichier CSV\n",
    "    summary_file = f'{mseed_file}_summary.csv'\n",
    "    summary_df.to_csv(summary_file, index=False)\n",
    "\n",
    "    print(f\"Résumé sauvegardé dans : {summary_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
